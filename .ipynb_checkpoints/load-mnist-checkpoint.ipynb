{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "fa0e24d7-27ec-40b0-8b1e-1bff80e5848d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "b1a85e49-e21a-4b4c-bd8c-78e71f01b666",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries and functions to load the data\n",
    "from digits import get_mnist\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, SubsetRandomSampler, Subset\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "a91fd081-aa60-4252-bdd8-f6cdd7275e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download training data from open datasets.\n",
    "training_data = datasets.MNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")\n",
    "\n",
    "# Download test data from open datasets.\n",
    "test_data = datasets.MNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "9b707d17-e24d-41e0-a1c0-55a80fd7f0e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13333986796150631047"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "torch.random.seed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "47cfa6c5-c968-4a2f-8359-c161215f46c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 1)\n",
      "Labels are [0 1 2 3 4 5 6 7 8 9] 10000\n",
      "For i: 0 there are 1000\n",
      "For i: 1 there are 1000\n",
      "For i: 2 there are 1000\n",
      "For i: 3 there are 1000\n",
      "For i: 4 there are 1000\n",
      "For i: 5 there are 1000\n",
      "For i: 6 there are 1000\n",
      "For i: 7 there are 1000\n",
      "For i: 8 there are 1000\n",
      "For i: 9 there are 1000\n",
      "Unique Labels are [0 1 2 3 4 5 6 7 8 9] total data taken for labeled mask 10000\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2 22 25 36 45 48 93 94 95 96]\n",
      "[  5  31  43  44 105 116 117 134 138 156]\n",
      "[  8  16  20  58  73  84 106 109 110 120]\n",
      "[ 4 21 24 28 40 46 49 50 53 69]\n",
      "[ 0 12 15 17 23 27 32 33 34 47]\n",
      "[  3  13  35  38  42  56  70  71  72 103]\n",
      "[18 30 51 52 59 62 63 67 78 91]\n",
      "[ 1  9 10 11 14 26 41 65 68 99]\n",
      "[ 6  7 19 37 39 57 74 75 76 79]\n",
      "[ 29  55  64  80  87  92 101 107 122 131]\n",
      "100 This is main\n",
      "0\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'DataLoader' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[106], line 65\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m5\u001b[39m):\n\u001b[1;32m     64\u001b[0m     \u001b[38;5;28mprint\u001b[39m(i)\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m test \u001b[38;5;129;01min\u001b[39;00m labeled_dataset:\n\u001b[1;32m     66\u001b[0m         \u001b[38;5;28mprint\u001b[39m(test)\n\u001b[1;32m     71\u001b[0m \u001b[38;5;66;03m# DataLoader for labeled data\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/utils/data/dataset.py:356\u001b[0m, in \u001b[0;36mSubset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    354\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(idx, \u001b[38;5;28mlist\u001b[39m):\n\u001b[1;32m    355\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m idx]]\n\u001b[0;32m--> 356\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'DataLoader' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "desired_num_samples = 10000\n",
    "examples_per_class = 1000\n",
    "\n",
    "selected_indices = []\n",
    "\n",
    "# Getting 1000 samples from each class\n",
    "# Iterate through each class to select the desired number of examples\n",
    "for class_idx in range(10):  # MNIST has 10 classes (digits 0 to 9)\n",
    "    class_indices = [idx for idx, label in enumerate(training_data.targets) if label == class_idx]\n",
    "    selected_indices.extend(class_indices[:examples_per_class])\n",
    "\n",
    "# Create a SubsetRandomSampler with the selected indices\n",
    "subset_sampler = SubsetRandomSampler(selected_indices)\n",
    "# Create data loaders.\n",
    "# train_dataloader = DataLoader(training_data, batch_size=batch_size, sampler=subset_sampler)\n",
    "# test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
    "\n",
    "\n",
    "train_dataloader = DataLoader(training_data, sampler=subset_sampler)\n",
    "test_dataloader = DataLoader(test_data)\n",
    "\n",
    "X_input_image_arr = [X for batch, (X,y) in enumerate(train_dataloader)]\n",
    "Y_label_arr = [y for batch, (X,y) in enumerate(train_dataloader)]\n",
    "print(np.array(Y_label_arr).shape)\n",
    "\n",
    "\n",
    "total_number_of_samples = len(train_dataloader)\n",
    "labeled_sample_for_every_class = 10\n",
    "\n",
    "unique_labels = np.unique([y for batch, (X,y) in enumerate(train_dataloader)])\n",
    "print(\"Labels are\", unique_labels, total_number_of_samples)\n",
    "\n",
    "## CHECKING IF EVERY CLASS CONTAINS 1000 images\n",
    "for i in unique_labels:\n",
    "    print('For i:', i, 'there are',np.count_nonzero(np.array(Y_label_arr) == 8))\n",
    "\n",
    "labeled_mask = np.zeros(total_number_of_samples, dtype=bool)\n",
    "\n",
    "\n",
    "print(\"Unique Labels are\", np.unique([y for batch, (X,y) in enumerate(train_dataloader)]),'total data taken for labeled mask', len(labeled_mask))\n",
    "\n",
    "\n",
    "img = X_input_image_arr[0].numpy().squeeze()\n",
    "plt.imshow(img, cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "for i in range(len(unique_labels)):\n",
    "    indices = np.where(np.array(Y_label_arr) == i)[0] # returns shuffled array of indices of each class, total 1000 data.\n",
    "    print(indices[:labeled_sample_for_every_class]) # first 10 data's indices\n",
    "    np.random.shuffle(indices)\n",
    "    labeled_mask[indices[:labeled_sample_for_every_class]] = True\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "labeled_dataset = Subset(train_dataloader, np.where(labeled_mask)[0]) # contains subset of 10 labeled data for each class so total = 10*10 =100\n",
    "unlabeled_dataset = Subset(train_dataloader, np.where(~labeled_mask)[0])\n",
    "\n",
    "print(len(labeled_dataset), 'This is main') \n",
    "\n",
    "\n",
    "\n",
    "# DataLoader for labeled data\n",
    "labeled_dataloader = DataLoader(labeled_dataset, batch_size=10, shuffle=True)\n",
    "\n",
    "# DataLoader for unlabeled data\n",
    "unlabeled_dataloader =DataLoader(unlabeled_dataset, batch_size=10, shuffle=True)\n",
    "\n",
    "print(len(labeled_dataloader))\n",
    "print(len(unlabeled_dataloader))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "5e98486e-3ce7-4257-bf60-6fb285e8a3b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=200, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=200, out_features=10, bias=True)\n",
      "    (3): ReLU()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 200),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(200, 10),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "# model = NeuralNetwork().to(device)\n",
    "model = NeuralNetwork()\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "c32fe53a-55b3-41fa-a206-07b50a506576",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "4d4b1911-17d7-4553-a00b-399838c57774",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_torch(dataloader, model, loss_fn, optimizer):\n",
    "    # size = len(dataloader.dataset)\n",
    "    size = len(dataloader)\n",
    "    print()\n",
    "    \n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        # X, y = X.to(device), y.to(device)\n",
    "        X, y = X, y\n",
    "        \n",
    "\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), (batch + 1) * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "b1f97a1c-47d6-4bae-87c2-80679167bc43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_torch(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            # X, y = X.to(device), y.to(device)\n",
    "            X, y = X, y\n",
    "            \n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "e68fde5d-f2d9-449f-afbe-0ee61264953b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'DataLoader' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[99], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mt\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m-------------------------------\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m     \u001b[43mtrain_torch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabeled_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m     test_torch(test_dataloader, model, loss_fn)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDone!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[75], line 7\u001b[0m, in \u001b[0;36mtrain_torch\u001b[0;34m(dataloader, model, loss_fn, optimizer)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m()\n\u001b[1;32m      6\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch, (X, y) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(dataloader):\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;66;03m# X, y = X.to(device), y.to(device)\u001b[39;00m\n\u001b[1;32m      9\u001b[0m     X, y \u001b[38;5;241m=\u001b[39m X, y\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;66;03m# Compute prediction error\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/utils/data/dataset.py:356\u001b[0m, in \u001b[0;36mSubset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    354\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(idx, \u001b[38;5;28mlist\u001b[39m):\n\u001b[1;32m    355\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m idx]]\n\u001b[0;32m--> 356\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'DataLoader' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "# This can be uncommented when you need to torch\n",
    "epochs = 5\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_torch(labeled_dataset, model, loss_fn, optimizer)\n",
    "    test_torch(test_dataloader, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0ffbe78d-bad9-4fe8-98e1-42c13568e567",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique labels [0 1 2 3 4 5 6 7 8 9]\n",
      "Category 5: 1000 samples\n",
      "Category 0: 1000 samples\n",
      "Category 2: 1000 samples\n",
      "Category 4: 1000 samples\n",
      "Category 7: 1000 samples\n",
      "Category 8: 1000 samples\n",
      "Category 6: 1000 samples\n",
      "Category 1: 1000 samples\n",
      "Category 9: 1000 samples\n",
      "Category 3: 1000 samples\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'labels' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 40\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;66;03m# Randomly select samples from each category\u001b[39;00m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m label \u001b[38;5;129;01min\u001b[39;00m unique_labels:\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;66;03m# Find indices of samples with the current label\u001b[39;00m\n\u001b[0;32m---> 40\u001b[0m     indices \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mwhere(\u001b[43mlabels\u001b[49m \u001b[38;5;241m==\u001b[39m label)[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;66;03m# Randomly select 'samples_per_category' samples from the current category\u001b[39;00m\n\u001b[1;32m     43\u001b[0m     selected_indices \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mchoice(indices, size\u001b[38;5;241m=\u001b[39msamples_per_category, replace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'labels' is not defined"
     ]
    }
   ],
   "source": [
    "# Assuming the last column contains category labels\n",
    "# training_data_labels = training_data[:, -1]\n",
    "\n",
    "# Get unique category labels\n",
    "unique_labels = np.unique([y for batch, (X,y) in enumerate(train_dataloader)])\n",
    "\n",
    "print(\"Unique labels\", unique_labels)\n",
    "# print(\n",
    "\n",
    "# Set the number of samples you want to select from each category\n",
    "samples_per_category = 10\n",
    "\n",
    "# Initialize an empty array to store selected samples\n",
    "# selected_samples = np.empty((0, data.shape[1]))\n",
    "\n",
    "\n",
    "def count_samples_per_category(dataloader):\n",
    "    category_counts = {}\n",
    "\n",
    "    for _, labels in dataloader:\n",
    "        for label in labels:\n",
    "            category_counts[label.item()] = category_counts.get(label.item(), 0) + 1\n",
    "\n",
    "    return category_counts\n",
    "\n",
    "\n",
    "\n",
    "# Count the total number of samples in each category\n",
    "category_counts = count_samples_per_category(train_dataloader)\n",
    "\n",
    "# Print the results\n",
    "for category, count in category_counts.items():\n",
    "    print(f\"Category {category}: {count} samples\")\n",
    "\n",
    "\n",
    "\n",
    "# Randomly select samples from each category\n",
    "for label in unique_labels:\n",
    "    # Find indices of samples with the current label\n",
    "    indices = np.where(labels == label)[0]\n",
    "\n",
    "    # Randomly select 'samples_per_category' samples from the current category\n",
    "    selected_indices = np.random.choice(indices, size=samples_per_category, replace=False)\n",
    "\n",
    "    # Append selected samples to the result array\n",
    "    selected_samples = np.vstack((selected_samples, data[selected_indices]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "726ff0ab-6dac-4269-95ff-8875f37dbedc",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mnist' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[93], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Load the MNIST dataset\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m (x_train, y_train), (x_test, y_test) \u001b[38;5;241m=\u001b[39m \u001b[43mmnist\u001b[49m\u001b[38;5;241m.\u001b[39mload_data()\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Combine training and test datasets to get the full dataset\u001b[39;00m\n\u001b[1;32m      5\u001b[0m x_full \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate((x_train, x_test), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'mnist' is not defined"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
